"""
Sync Plan Executor Service for Phase 2 Seat Pack Synchronization

This module executes sync plans generated by the diffing algorithm,
handling database operations in the correct order while respecting
manual overrides and handling edge cases like pack re-activation.
Includes StubHub bulk inventory API integration for external POS deletions.
"""

from typing import List, Dict, Optional, Any
from django.db import transaction
from django.utils import timezone
from .seat_pack_sync import SyncPlan, CreationAction, UpdateAction, DelistAction, SyncAction
from .stubhub_bulk_api import process_sync_plan_with_stubhub
from .stubhub_inventory_creator import StubHubInventoryCreator
from ..models.seat_packs import SeatPack
from ..models import ScrapeJob, Zone, Performance, Event, Level
import logging
import json

logger = logging.getLogger(__name__)


class SyncPlanExecutor:
    """
    Executes sync plans against the database with proper transaction handling
    and comprehensive logging. Focus: Database operations only.
    """
    
    def __init__(self, source_website: str, scrape_job: ScrapeJob, zones_map: Dict[str, Zone]):
        """
        Initialize the executor with context for the sync operation.
        
        Args:
            source_website: Source website identifier
            scrape_job: Current scrape job for audit trail
            zones_map: Mapping of zone_id to Zone objects
        """
        self.source_website = source_website
        self.scrape_job = scrape_job
        self.zones_map = zones_map
        
    def _determine_seat_pack_level(self, seat_pack_data, scraped_data=None) -> Optional['Level']:
        """
        Determine level for a seat pack based on its actual seats.
        
        Zones can span multiple levels, so we need to determine the level
        dynamically based on the pack's actual seat composition.
        
        Args:
            seat_pack_data: SeatPackData object containing seat information
            scraped_data: Optional ScrapedData for seat lookup (not available in sync)
            
        Returns:
            Level object if found, None otherwise
        """
        try:
            # Import here to avoid circular imports
            from ..models import Seat, Level
            
            # Method 1: Check if pack data has explicit level
            if hasattr(seat_pack_data, 'level') and seat_pack_data.level:
                if isinstance(seat_pack_data.level, str):
                    # Convert level_id string to Level object
                    try:
                        return Level.objects.get(source_level_id=seat_pack_data.level, source_website=self.source_website)
                    except Level.DoesNotExist:
                        logger.warning(f"Level with source_level_id '{seat_pack_data.level}' not found")
                else:
                    # Already a Level object
                    return seat_pack_data.level
            
            # Method 1b: Check if pack data has explicit level_id
            if hasattr(seat_pack_data, 'level_id') and seat_pack_data.level_id:
                try:
                    level = Level.objects.get(source_level_id=seat_pack_data.level_id, source_website=self.source_website)
                    logger.debug(f"Successfully resolved level_id '{seat_pack_data.level_id}' to Level object: {level}")
                    return level
                except Level.DoesNotExist:
                    logger.warning(f"Level with source_level_id '{seat_pack_data.level_id}' not found for website '{self.source_website}'")
            
            # Method 2: Determine level from pack's actual seats in database
            if hasattr(seat_pack_data, 'seat_ids') and seat_pack_data.seat_ids:
                # Count seats by level for this specific pack
                level_counts = {}
                
                for seat_id in seat_pack_data.seat_ids:
                    try:
                        # Get seat and its section's level
                        seat = Seat.objects.select_related(
                            'section_id__level_id'
                        ).get(source_seat_id=seat_id, source_website=self.source_website)
                        
                        if seat.section_id and seat.section_id.level_id:
                            level = seat.section_id.level_id
                            level_counts[level.internal_level_id] = {
                                'level': level,
                                'count': level_counts.get(level.internal_level_id, {}).get('count', 0) + 1
                            }
                    except Seat.DoesNotExist:
                        continue
                
                # Return level with most seats (majority rule)
                if level_counts:
                    majority_level_data = max(level_counts.values(), key=lambda x: x['count'])
                    logger.debug(f"Pack {seat_pack_data.pack_id}: Determined level {majority_level_data['level'].internal_level_id} "
                               f"({majority_level_data['count']} seats)")
                    return majority_level_data['level']
            
            # Method 3: Fall back to zone-based level lookup (first seat in zone)
            if hasattr(seat_pack_data, 'zone_id') and seat_pack_data.zone_id in self.zones_map:
                zone = self.zones_map[seat_pack_data.zone_id]
                return self._get_level_for_zone(zone)
            
            logger.debug(f"No level found for pack {seat_pack_data.pack_id}")
            return None
            
        except Exception as e:
            logger.error(f"Error determining level for pack {seat_pack_data.pack_id}: {e}")
            return None
        
    def _get_level_for_zone(self, zone: Zone) -> Optional['Level']:
        """
        Efficiently derive the level for a seat pack based on its zone.
        
        This method finds the level by looking up the zone's associated seats
        and their sections. If multiple levels are found, returns the most common one.
        
        Args:
            zone: Zone object to find the level for
            
        Returns:
            Level object if found, None otherwise
        """
        try:
            # Import here to avoid circular imports
            from ..models import Seat, Level
            
            # Get the first seat in this zone and return its section's level
            # Use select_related to avoid N+1 queries
            seat_with_level = Seat.objects.filter(
                zone_id=zone
            ).select_related(
                'section_id__level_id'
            ).first()
            
            if seat_with_level and seat_with_level.section_id and seat_with_level.section_id.level_id:
                return seat_with_level.section_id.level_id
            
            logger.debug(f"No level found for zone {zone.internal_zone_id} (expected for zones spanning multiple levels)")
            return None
            
        except Exception as e:
            logger.error(f"Error getting level for zone {zone.internal_zone_id}: {e}")
            return None

    def _resolve_level_from_pack_data(self, pack_data, zone: Zone) -> Optional['Level']:
        """
        Resolve Level object from SeatPackData, handling both string level_id and Level objects.
        
        This method implements the correct level resolution logic:
        1. Try to use pack_data.level if it's a Level object
        2. Try to convert pack_data.level_id (string) to Level object
        3. Fall back to zone-based level lookup
        
        Args:
            pack_data: SeatPackData object containing level information
            zone: Zone object for fallback level lookup
            
        Returns:
            Level object if found, None otherwise
        """
        try:
            # Import here to avoid circular imports
            from ..models import Level
            
            # Check if pack_data has a Level object directly
            if hasattr(pack_data, 'level') and pack_data.level:
                if not isinstance(pack_data.level, str):
                    # Already a Level object
                    return pack_data.level
                else:
                    # It's a string level_id, try to convert to Level object
                    level_id_string = pack_data.level
                    try:
                        level = Level.objects.get(source_level_id=level_id_string, source_website=self.source_website)
                        logger.debug(f"Successfully resolved level_id '{level_id_string}' to Level object: {level}")
                        return level
                    except Level.DoesNotExist:
                        logger.warning(f"Level with source_level_id '{level_id_string}' not found for website '{self.source_website}', trying zone lookup")
            
            # Check if pack_data has level_id field
            if hasattr(pack_data, 'level_id') and pack_data.level_id:
                try:
                    level = Level.objects.get(source_level_id=pack_data.level_id, source_website=self.source_website)
                    logger.debug(f"Successfully resolved level_id '{pack_data.level_id}' to Level object: {level}")
                    return level
                except Level.DoesNotExist:
                    logger.warning(f"Level with source_level_id '{pack_data.level_id}' not found for website '{self.source_website}', trying zone lookup")
            
            # Fall back to zone-based level lookup
            logger.debug(f"No direct level found in pack_data, falling back to zone-based lookup for zone {zone.internal_zone_id}")
            return self._get_level_for_zone(zone)
            
        except Exception as e:
            logger.error(f"Error resolving level from pack data: {e}")
            return None
        
    @transaction.atomic
    def execute_sync_plan(self, sync_plan: SyncPlan, performance: Performance, event: Event) -> Dict[str, int]:
        """
        Executes a complete sync plan in the correct order with transaction safety.
        
        The order of operations is critical:
        1. Delistings first (remove from active pool)
        2. Updates to existing active packs
        3. Creations and re-activations last
        
        Args:
            sync_plan: Complete sync plan to execute
            
        Returns:
            Dictionary with counts of operations performed
        """

        
        results = {
            'delistings': 0,
            'updates': 0,
            'creations': 0,
            'reactivations': 0,
            'errors': 0
        }
        
        try:
            # Phase 1: Execute delistings (database only)
            delist_results = self._execute_delist_actions(sync_plan.delist_actions)
            results['delistings'] = delist_results
            
            # Phase 2: Execute updates (price updates only)
            update_results = self._execute_update_actions(sync_plan.update_actions)
            results['updates'] = update_results['updates']
            
            # Phase 3: Execute creations and re-activations
            creation_results = self._execute_creation_actions(sync_plan.creation_actions, performance, event)
            results['creations'] = creation_results['creations']
            results['reactivations'] = creation_results['reactivations']
            
            logger.info(f"Sync plan executed successfully: {results}")
            return results
            
        except Exception as e:
            logger.error(f"Sync plan execution failed: {str(e)}")
            results['errors'] = 1
            raise
    
    
    def _execute_update_actions(self, update_actions: List[UpdateAction]) -> Dict[str, int]:
        """
        Execute price update actions for functionally equivalent packs.
        
        Updates pricing information while setting synced_to_pos=False
        to indicate external POS sync service needs to handle updates.
        
        Args:
            update_actions: List of update actions with new price data
            
        Returns:
            Dictionary with update counts
        """
        if not update_actions:
            return {'updates': 0, 'errors': []}
        
        updated_count = 0
        errors = []
        
        logger.info(f"💰 PRICE UPDATES: Processing {len(update_actions)} price updates")
        
        for action in update_actions:
            try:
                pack_id = action.pack_id
                new_data = action.updated_data
                
                # Find the pack to update
                pack = SeatPack.objects.filter(
                    internal_pack_id=pack_id,
                    source_website=self.source_website,
                    pack_status='active'  # Only update active packs
                ).first()
                
                if not pack:
                    logger.warning(f"⚠️ Pack {pack_id} not found for price update")
                    continue
                
                # Store old values for logging
                old_pack_price = pack.pack_price
                old_total_price = pack.total_price
                
                # Update pricing fields and mark for external POS sync
                pack.pack_price = new_data.pack_price
                pack.total_price = new_data.total_price
                pack.updated_at = timezone.now()
                
                # Mark as needing external POS sync due to price change
                pack.synced_to_pos = False
                logger.debug(f"🔄 Pack {pack_id} marked for external POS sync: {old_pack_price} → {new_data.pack_price}")
                
                # Save with only the updated fields to avoid version conflicts
                pack.save(update_fields=['pack_price', 'total_price', 'synced_to_pos', 'updated_at'])
                
                updated_count += 1
                logger.info(f"✅ Updated pack {pack_id}: price ${old_pack_price} → ${new_data.pack_price}")
                
            except Exception as e:
                error_msg = f"Failed to update pack {action.pack_id}: {str(e)}"
                logger.error(f"❌ {error_msg}")
                errors.append(error_msg)
        
        logger.info(f"🏁 Price updates complete: {updated_count} updated, {len(errors)} errors")
        return {'updates': updated_count, 'errors': errors}
    
    def _execute_delist_actions(self, delist_actions: List[DelistAction]) -> int:
        """
        Execute all delist actions using new 4-dimensional model fields.
        Uses intelligent delisting based on the reason:
        - 'transformed': Sets pack_status='inactive' (seats changed, pack no longer valid)
        - 'vanished': Sets pack_status='inactive' (seats disappeared completely)  
        - Other reasons: Sets pos_status='inactive' but keeps pack_status='active'
        
        Args:
            delist_actions: List of packs to delist
            
        Returns:
            Number of packs successfully delisted
        """
        if not delist_actions:
            return 0
        
        delisted_count = 0
        
        # Group actions by delist strategy
        full_deactivation_reasons = ['transformed', 'vanished']
        full_deactivation_actions = [a for a in delist_actions if a.reason in full_deactivation_reasons]
        pos_only_actions = [a for a in delist_actions if a.reason not in full_deactivation_reasons]
        
        # Handle full deactivation (pack becomes completely inactive)
        if full_deactivation_actions:
            pack_ids = [action.pack_id for action in full_deactivation_actions]
            logger.info(f"🚫 FULL DEACTIVATION: Marking {len(pack_ids)} packs as completely inactive (transformed/vanished)")
            
            updated_count = SeatPack.objects.filter(
                internal_pack_id__in=pack_ids,
                source_website=self.source_website,
                pack_status='active'  # Only deactivate active packs
            ).update(
                pack_status='inactive',      # DIMENSION 1: Deactivate completely
                pos_status='inactive',       # DIMENSION 2: Remove from POS
                pack_state='transformed',    # DIMENSION 3: Mark as transformed (terminal state)
                synced_to_pos=False,        # Needs POS cleanup
                updated_at=timezone.now()
            )
            
            # Set individual delist reasons
            for action in full_deactivation_actions:
                try:
                    SeatPack.objects.filter(
                        internal_pack_id=action.pack_id,
                        source_website=self.source_website,
                        pack_status='inactive'
                    ).update(delist_reason=action.reason)
                    delisted_count += 1
                    logger.debug(f"✅ Fully deactivated pack {action.pack_id}: pack_status='inactive', reason='{action.reason}'")
                except Exception as e:
                    logger.error(f"❌ Failed to set delist reason for pack {action.pack_id}: {str(e)}")
        
        # Handle POS-only delisting (pack stays active in our system but removed from POS)
        if pos_only_actions:
            pack_ids = [action.pack_id for action in pos_only_actions]
            logger.info(f"🔄 POS DELISTING: Removing {len(pack_ids)} packs from POS only (keeping active in system)")
            
            updated_count = SeatPack.objects.filter(
                internal_pack_id__in=pack_ids,
                source_website=self.source_website,
                pack_status='active'        # Only delist active packs
            ).update(
                pos_status='inactive',       # DIMENSION 2: Remove from POS
                pack_state='delist',        # DIMENSION 3: Mark as delisted
                synced_to_pos=False,        # Needs POS cleanup
                updated_at=timezone.now()
            )
            
            # Set individual delist reasons
            for action in pos_only_actions:
                try:
                    SeatPack.objects.filter(
                        internal_pack_id=action.pack_id,
                        source_website=self.source_website,
                        pos_status='inactive'
                    ).update(delist_reason=action.reason)
                    delisted_count += 1
                    logger.debug(f"✅ POS delisted pack {action.pack_id}: pos_status='inactive', reason='{action.reason}'")
                except Exception as e:
                    logger.error(f"❌ Failed to set delist reason for pack {action.pack_id}: {str(e)}")
        
        logger.info(f"🏁 Delisting complete: {delisted_count} packs processed using four-dimensional model")
        return delisted_count
    
    def _execute_creation_actions(self, creation_actions: List[CreationAction], performance: Performance, event: Event) -> Dict[str, Any]:
        """
        Execute all creation actions, handling both new creations and re-activations.
        
        This handles the "zombie pack" scenario where a previously delisted pack
        reappears with the same deterministic ID.
        
        Args:
            creation_actions: List of packs to create
            
        Returns:
            Dictionary with creation counts and successful actions for inventory creation
        """
        if not creation_actions:
            return {'creations': 0, 'reactivations': 0, 'successful_actions': []}
        
        created_count = 0
        reactivated_count = 0
        successful_actions = []  # Track actions that actually resulted in creation/reactivation
        
        for action in creation_actions:
            try:
                pack_data = action.pack_data
                pack_id = pack_data.pack_id
                zone = self.zones_map.get(pack_data.zone_id)
                
                if not zone:
                    logger.error(f"Zone {pack_data.zone_id} not found for pack {pack_id}")
                    continue
                
                # Check if this pack already exists (potentially inactive)
                # First check by internal_pack_id
                existing_pack = SeatPack.objects.filter(
                    internal_pack_id=pack_id
                ).first()
                
                # If not found by internal_pack_id, check by unique constraint fields
                # to prevent constraint violations
                if not existing_pack:
                    # Get the level first to include it in the constraint check
                    pack_level = self._determine_seat_pack_level(pack_data)
                    
                    existing_pack = SeatPack.objects.filter(
                        zone_id=zone,
                        row_label=pack_data.row_label,
                        start_seat_number=pack_data.start_seat_number,
                        end_seat_number=pack_data.end_seat_number,
                        scrape_job_key=self.scrape_job,
                        level=pack_level
                    ).first()
                    
                    if existing_pack:
                        logger.warning(f"🔍 DUPLICATE DETECTION: Found existing pack {existing_pack.internal_pack_id} "
                                     f"with same constraint fields as new pack {pack_id}. "
                                     f"Zone: {pack_data.zone_id}, Row: {pack_data.row_label}, "
                                     f"Seats: {pack_data.start_seat_number}-{pack_data.end_seat_number}, "
                                     f"Level: {pack_level.internal_level_id if pack_level else 'None'}")
                
                if existing_pack:
                    # This is a RE-ACTIVATION scenario or duplicate prevention
                    if existing_pack.pack_status != 'active':  # Use new four-dimensional field
                        # Reactivate using four-dimensional model
                        existing_pack.pack_status = 'active'       # DIMENSION 1: Reactivate in our system
                        existing_pack.pos_status = 'pending'       # DIMENSION 2: Needs POS sync
                        existing_pack.pack_state = action.action_type  # DIMENSION 3: How it came back (create/split/etc.)
                        existing_pack.delist_reason = None         # DIMENSION 4: Clear delist reason
                        existing_pack.synced_to_pos = False        # Needs POS sync
                        
                        # Update content fields
                        existing_pack.pack_price = pack_data.pack_price
                        existing_pack.total_price = pack_data.total_price
                        existing_pack.seat_keys = pack_data.seat_ids
                        existing_pack.scrape_job_key = self.scrape_job
                        existing_pack.updated_at = timezone.now()

                        # Legacy fields (for backward compatibility)
                        existing_pack.manually_delisted = False
                        existing_pack.source_pack_ids = action.source_pack_ids

                        # Update context fields
                        existing_pack.performance = performance
                        if hasattr(pack_data, 'event'):
                            existing_pack.event = event
                        
                        # Enhanced level assignment logic (reuse if already calculated)
                        if 'pack_level' not in locals():
                            pack_level = self._determine_seat_pack_level(pack_data)
                        existing_pack.level = pack_level
                            
                        existing_pack.save()
                        reactivated_count += 1
                        successful_actions.append(action)  # Track successful reactivation
                        logger.debug(f"🔄 Reactivated pack {existing_pack.internal_pack_id} using four-dimensional model")
                    else:
                        logger.debug(f"🔄 SKIP DUPLICATE: Pack {existing_pack.internal_pack_id} already active, skipping creation of {pack_id}")
                else:
                    # This is a TRUE NEW CREATION
                    # Enhanced level assignment logic (reuse if already calculated)
                    if 'pack_level' not in locals():
                        pack_level = self._determine_seat_pack_level(pack_data)
                    
                    try:
                        SeatPack.objects.create(
                            internal_pack_id=pack_id,
                            zone_id=zone,
                            scrape_job_key=self.scrape_job,
                            source_pack_id=pack_data.pack_id,
                            source_website=pack_data.source_website,
                            row_label=pack_data.row_label,
                            start_seat_number=pack_data.start_seat_number,
                            end_seat_number=pack_data.end_seat_number,
                            pack_size=pack_data.pack_size,
                            pack_price=pack_data.pack_price,
                            total_price=pack_data.total_price,
                            seat_keys=pack_data.seat_ids,
                            
                            # Context fields (derive from zone for data integrity)
                            performance=performance,
                            event=event,
                            level=pack_level,

                            # Four-dimensional model fields (new)
                            pack_status='active',      # DIMENSION 1: Active in our system
                            pos_status='pending',      # DIMENSION 2: Needs POS sync
                            pack_state=action.action_type,  # DIMENSION 3: How it came to be (create/split/merge/shrink)
                            delist_reason=None,        # DIMENSION 4: Not delisted
                            synced_to_pos=False,       # Needs POS sync
                            
                            # Legacy sync fields (for backward compatibility)
                            manually_delisted=False,
                            source_pack_ids=action.source_pack_ids
                        )
                        created_count += 1
                        successful_actions.append(action)  # Track successful creation
                        logger.debug(f"✅ Created new pack {pack_id}: {action.action_type}")
                    except Exception as creation_error:
                        # Handle specific constraint violations
                        if 'unique constraint' in str(creation_error).lower():
                            logger.error(f"❌ CONSTRAINT VIOLATION: Attempted to create duplicate pack {pack_id}. "
                                       f"Zone: {pack_data.zone_id}, Row: {pack_data.row_label}, "
                                       f"Seats: {pack_data.start_seat_number}-{pack_data.end_seat_number}, "
                                       f"Level: {pack_level.internal_level_id if pack_level else 'None'}, "
                                       f"ScrapeJob: {self.scrape_job.pk}. Error: {creation_error}")
                            
                            # Try to find the existing pack one more time for debugging
                            duplicate_pack = SeatPack.objects.filter(
                                zone_id=zone,
                                row_label=pack_data.row_label,
                                start_seat_number=pack_data.start_seat_number,
                                end_seat_number=pack_data.end_seat_number,
                                scrape_job_key=self.scrape_job,
                                level=pack_level
                            ).first()
                            
                            if duplicate_pack:
                                logger.error(f"🔍 DUPLICATE PACK FOUND: {duplicate_pack.internal_pack_id} "
                                           f"(active: {duplicate_pack.is_active})")
                            else:
                                logger.error(f"🤔 UNEXPECTED: No duplicate pack found despite constraint violation")
                        else:
                            # Re-raise non-constraint violations
                            raise creation_error
                    
            except Exception as e:
                logger.error(f"Failed to create/reactivate pack {action.pack_data.pack_id}: {str(e)}")
        
        logger.info(f"Created {created_count} new packs, reactivated {reactivated_count} packs")
        logger.info(f"Passing {len(successful_actions)} successful actions to inventory creator")
        return {
            'creations': created_count, 
            'reactivations': reactivated_count,
            'successful_actions': successful_actions
        }


class SyncPlanValidator:
    """
    Validates sync plans before execution to catch potential issues.
    """
    
    @staticmethod
    def validate_sync_plan(sync_plan: SyncPlan, zones_map: Dict[str, Zone]) -> List[str]:
        """
        Validates a sync plan and returns a list of validation errors.
        
        Args:
            sync_plan: Sync plan to validate
            zones_map: Available zones for validation
            
        Returns:
            List of validation error messages (empty if valid)
        """
        errors = []
        
        # Validate creation actions
        for action in sync_plan.creation_actions:
            if action.pack_data.zone_id not in zones_map:
                errors.append(f"Creation action references unknown zone: {action.pack_data.zone_id}")
            
            if action.action_type not in ['create', 'split', 'shrink', 'merge']:
                errors.append(f"Invalid action type: {action.action_type}")
            
            if not action.pack_data.pack_id:
                errors.append("Creation action missing pack_id")
        
        # No update actions to validate - we only delete and create
        
        # Validate delist actions
        for action in sync_plan.delist_actions:
            if not action.pack_id:
                errors.append("Delist action missing pack_id")
            
            if action.reason not in ['transformed', 'vanished']:
                errors.append(f"Invalid delist reason: {action.reason}")
        
        return errors


def execute_seat_pack_synchronization(
    existing_packs: List[SeatPack],
    new_packs: List,
    source_website: str,
    scrape_job: ScrapeJob,
    zones_map: Dict[str, Zone],
    performance: Performance,
    event: Event
) -> Dict[str, int]:
    """
    High-level function to execute complete seat pack synchronization.
    
    This is the main entry point for integrating sync into the scraping workflow.
    Focus: Database operations only - no external POS synchronization.
    
    Args:
        existing_packs: Current active seat packs from database
        new_packs: Newly generated seat pack data
        source_website: Source website identifier
        scrape_job: Current scrape job
        zones_map: Zone mapping for validation
        performance: Performance object
        event: Event object
        
    Returns:
        Dictionary with operation counts and results
    """
    from .seat_pack_sync import diff_seat_packs, prepare_seat_pack_data_for_sync

    try:
        # Prepare data for sync
        prepared_new_packs = prepare_seat_pack_data_for_sync(new_packs)
        sync_plan = diff_seat_packs(existing_packs, prepared_new_packs)
        validator = SyncPlanValidator()
        validation_errors = validator.validate_sync_plan(sync_plan, zones_map)
        
        if validation_errors:
            logger.error(f"❌ SYNC EXECUTOR ERROR: Sync plan validation failed: {validation_errors}")
            return {'errors': len(validation_errors), 'validation_errors': validation_errors}
        
        logger.info("✅ SYNC EXECUTOR DEBUG: Sync plan validation passed")
        
        # Execute sync plan
        logger.info("⚡ SYNC EXECUTOR DEBUG: Executing sync plan...")
        executor = SyncPlanExecutor(source_website, scrape_job, zones_map)
        results = executor.execute_sync_plan(sync_plan, performance, event)
        
        logger.info(f"🏁 SYNC EXECUTOR DEBUG: Sync execution completed successfully: {results}")
        return results
        
    except Exception as e:
        logger.error(f"❌ SYNC EXECUTOR ERROR: Seat pack synchronization failed: {str(e)}", exc_info=True)
        return {'errors': 1, 'error_message': str(e)}